{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook performs the following tasks:\n",
    "1. Downloads NOAA climate data by station.\n",
    "2. Preprocesses the downloaded data to prepare it for analysis.\n",
    "\n",
    "Author: Espoir\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import shutil\n",
    "import warnings as ws\n",
    "ws.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'G:\\Master_DJAMAN\\Database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to download: 949\n",
      "\n",
      "Progress: [==================================================] 949/949\n",
      "All files downloaded and decompressed.\n"
     ]
    }
   ],
   "source": [
    "### Files needed: ghcnd-stations , readme on NOAA to check the stations code\n"
     You can get ghcnd-stations file from https://www.ncei.noaa.gov/pub/data/ghcn/daily/\n",
    "\"\"\"\n",
    "This script downloads and decompresses climate data files from the NOAA website. \n",
    "This code was designed for Quebec, need to improve it to make it general function to download  for others stations\n",
    "The script performs the following steps:\n",
    "1. Defines the base URL for the NOAA climate data.\n",
    "2. Fetches the content of the web directory at the base URL.\n",
    "3. Parses the HTML content to find all links that start with 'CA007'.\n",
    "4. Creates a directory named 'CA007_files' to store the downloaded files.\n",
    "5. Downloads and decompresses each file.\n",
    "\"\"\"\n",
    "\n",
    "# Define the base URL\n",
    "base_url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/by_station/'\n",
    "\n",
    "# Fetch the content of the web directory\n",
    "response = requests.get(base_url)\n",
    "response.raise_for_status()  # Ensure we notice bad responses\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "station_code = 'CA007'\n",
    "# Find all links that start with 'CA007'\n",
    "links = soup.find_all('a')\n",
    "file_links = [link.get('href') for link in links if link.get('href').startswith(station_code)]\n",
    "\n",
    "# Create a directory to store the downloaded files\n",
    "os.makedirs(f'{station_code}_files', exist_ok=True)\n",
    "\n",
    "print(f\"Total files to download: {len(file_links)}\\n\")\n",
    "\n",
    "# Download and decompress each file with a progress indicator using tqdm\n",
    "for file_link in tqdm(file_links, desc=\"Downloading and decompressing files\", unit=\"file\"):\n",
    "    file_url = base_url + file_link\n",
    "    file_response = requests.get(file_url)\n",
    "    file_response.raise_for_status()  # Ensure we notice bad responses\n",
    "    \n",
    "    # Define the path for the compressed file and the decompressed file\n",
    "    compressed_file_path = os.path.join(f'{station_code}_files', file_link)\n",
    "    decompressed_file_path = os.path.splitext(compressed_file_path)[0]  # Remove .gz extension\n",
    "    \n",
    "    # Save the compressed file\n",
    "    with open(compressed_file_path, 'wb') as compressed_file:\n",
    "        compressed_file.write(file_response.content)\n",
    "    \n",
    "    # Decompress the file\n",
    "    with gzip.open(compressed_file_path, 'rb') as f_in:\n",
    "        with open(decompressed_file_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "    # Remove the compressed file after decompressing\n",
    "    os.remove(compressed_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 949/949 [48:36<00:00,  3.07s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data processing complete. File saved as 'processed_CA007_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the station code\n",
    "station_code = \"CA007\"  # Replace with your station code or pass it as a variable\n",
    "\n",
    "# Define the directory containing the station_code files\n",
    "directory = os.path.join(os.getcwd(), f\"{station_code}_files\")\n",
    "\n",
    "# Check if the output file already exists and ask if it should be overwritten\n",
    "output_file = f'processed_{station_code}_data.csv'\n",
    "if os.path.exists(output_file):\n",
    "    overwrite = input(f\"File '{output_file}' already exists. Overwrite? (y/n): \").strip().lower()\n",
    "    if overwrite != 'y':\n",
    "        print(\"Process aborted. No file was overwritten.\")\n",
    "        exit()\n",
    "\n",
    "# Initialize an empty DataFrame to store all processed data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the directory with a progress bar\n",
    "file_list = [f for f in os.listdir(directory) if f.startswith(station_code) and f.endswith('.csv')]\n",
    "for filename in tqdm(file_list, desc=\"Processing files\", unit=\"file\"):\n",
    "    # Define the full path to the CSV file\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    try:\n",
    "        # Read the file into a DataFrame\n",
    "        df = pd.read_csv(file_path, header=None, names=['Station', 'Date', 'Variable', 'Value', \"C1\", \"C2\", \"C3\", \"C4\"],\n",
    "                         dtype={'Station': str, 'Date': str, 'Variable': str, 'Value': str})\n",
    "        \n",
    "        # Filter out rows where the Date column is not valid\n",
    "        df = df[df['Date'].str.isdigit()]\n",
    "        \n",
    "        # Extract year, month, day from the Date column\n",
    "        df['Year'] = df['Date'].str[:4]\n",
    "        df['Month'] = df['Date'].str[4:6]\n",
    "        df['Day'] = df['Date'].str[6:8]\n",
    "        \n",
    "        # Convert Date column to proper date format\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d').dt.strftime('%Y/%m/%d')\n",
    "        \n",
    "        # Convert the Value column to numeric, setting errors='coerce' will replace invalid parsing with NaN\n",
    "        df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "        \n",
    "        # Pivot the DataFrame to have variables as columns\n",
    "        df_pivot = df.pivot(index=['Station', 'Date', 'Year', 'Month', 'Day'], columns='Variable', values='Value').reset_index()\n",
    "        \n",
    "        # Append the processed DataFrame to the all_data DataFrame\n",
    "        all_data = pd.concat([all_data, df_pivot], ignore_index=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Save the combined and processed data to a CSV file\n",
    "all_data.to_csv(output_file, index=False)\n",
    "print(f\"\\nData processing complete. File saved as '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'G:\\Master_DJAMAN\\Database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>StationName</th>\n",
       "      <th>Type</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97306</th>\n",
       "      <td>US1WVBY0002</td>\n",
       "      <td>39.5875</td>\n",
       "      <td>-77.9181</td>\n",
       "      <td>149.4</td>\n",
       "      <td>WV FALLING WATERS 2.4 NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72100</th>\n",
       "      <td>US1MDCV0022</td>\n",
       "      <td>38.3809</td>\n",
       "      <td>-76.4051</td>\n",
       "      <td>35.1</td>\n",
       "      <td>MD LUSBY 2.4 NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18565</th>\n",
       "      <td>BR001448000</td>\n",
       "      <td>-14.1500</td>\n",
       "      <td>-48.0800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>COLINAS DO SUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>ASN00055226</td>\n",
       "      <td>-30.7833</td>\n",
       "      <td>149.8833</td>\n",
       "      <td>-999.9</td>\n",
       "      <td>BLAIRMORE 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92607</th>\n",
       "      <td>US1TXMDL033</td>\n",
       "      <td>32.0253</td>\n",
       "      <td>-102.1357</td>\n",
       "      <td>859.5</td>\n",
       "      <td>TX MIDLAND 2.1 W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Station  Latitude  Longitude  Altitude               StationName  \\\n",
       "97306  US1WVBY0002   39.5875   -77.9181     149.4  WV FALLING WATERS 2.4 NW   \n",
       "72100  US1MDCV0022   38.3809   -76.4051      35.1           MD LUSBY 2.4 NE   \n",
       "18565  BR001448000  -14.1500   -48.0800       0.0            COLINAS DO SUL   \n",
       "10672  ASN00055226  -30.7833   149.8833    -999.9               BLAIRMORE 1   \n",
       "92607  US1TXMDL033   32.0253  -102.1357     859.5          TX MIDLAND 2.1 W   \n",
       "\n",
       "      Type Code  \n",
       "97306  NaN  NaN  \n",
       "72100  NaN  NaN  \n",
       "18565  NaN  NaN  \n",
       "10672  NaN  NaN  \n",
       "92607  NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station = pd.read_fwf(\"ghcnd-stations.txt\", \n",
    "                 widths=[12, 9, 9, 7, 29, 9, 12],  \n",
    "                 names=['Station', 'Latitude', 'Longitude', 'Altitude', 'StationName', 'Type', 'Code'])  # Adjust column names\n",
    "df_station.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  USE THIS CODE IF YOU DON'T FACE WITH MEMORY ISSUE\n",
    "# data = pd.read_csv('processed_CA007_data.csv')\n",
    "# # Set the 'Station' column as the index for both DataFrames\n",
    "# df_station.set_index('Station', inplace=True)\n",
    "# data.set_index('Station', inplace=True)\n",
    "\n",
    "# # Join the DataFrames\n",
    "# data = data.join(df_station, how='left')\n",
    "\n",
    "# # Reset index if you want to keep 'Station' as a column\n",
    "# data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_station.set_index('Station', inplace=True)\n",
    "\n",
    "# Process large file in chunks\n",
    "chunk_size = 100000  # Adjust based on memory capacity\n",
    "data_chunks = []  # List to hold processed chunks\n",
    "\n",
    "# Read the large CSV in chunks\n",
    "for chunk in pd.read_csv('processed_CA007_data.csv', chunksize=chunk_size):\n",
    "    # Set index and join with df_station\n",
    "    chunk.set_index('Station', inplace=True)\n",
    "    chunk = chunk.join(df_station, how='left')\n",
    "    chunk.reset_index(inplace=True)  # Reset index to keep 'Station' as a column\n",
    "    \n",
    "    # Append processed chunk to the list\n",
    "    data_chunks.append(chunk)\n",
    "\n",
    "# Concatenate all chunks\n",
    "data = pd.concat(data_chunks, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Station', 'Date', 'Year', 'Month', 'Day', 'MDPR', 'MDSF', 'PRCP',\n",
       "       'SNOW', 'TMAX', 'TMIN', 'TAVG', 'WDFG', 'WSFG', 'SNWD', 'PGTM', 'WT01',\n",
       "       'WT03', 'WT04', 'WT06', 'WT08', 'WT09', 'WT16', 'WT18', 'Latitude',\n",
       "       'Longitude', 'Altitude', 'StationName', 'Type', 'Code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>StationName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7331752</th>\n",
       "      <td>CA007060400</td>\n",
       "      <td>1997/05/05</td>\n",
       "      <td>1997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.3333</td>\n",
       "      <td>-71.0000</td>\n",
       "      <td>159.0</td>\n",
       "      <td>QC BAGOTVILLE A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482906</th>\n",
       "      <td>CA007021840</td>\n",
       "      <td>2014/11/21</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.1500</td>\n",
       "      <td>-71.8000</td>\n",
       "      <td>259.0</td>\n",
       "      <td>QC COATICOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424690</th>\n",
       "      <td>CA007035360</td>\n",
       "      <td>1961/05/28</td>\n",
       "      <td>1961</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.9167</td>\n",
       "      <td>-74.2667</td>\n",
       "      <td>290.0</td>\n",
       "      <td>QC MORIN HEIGHTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5609901</th>\n",
       "      <td>CA007048421</td>\n",
       "      <td>1980/07/20</td>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.7000</td>\n",
       "      <td>-59.3167</td>\n",
       "      <td>9.0</td>\n",
       "      <td>QC TETE A LA BALEINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833304</th>\n",
       "      <td>CA007040440</td>\n",
       "      <td>1999/08/27</td>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.1333</td>\n",
       "      <td>-68.2000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>QC BAIE-COMEAU A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Station        Date  Year  Month  Day  PRCP  SNOW   TMAX   TMIN  \\\n",
       "7331752  CA007060400  1997/05/05  1997      5    5   0.0   0.0  117.0  -35.0   \n",
       "1482906  CA007021840  2014/11/21  2014     11   21   0.0   0.0  -55.0  -95.0   \n",
       "4424690  CA007035360  1961/05/28  1961      5   28   0.0   0.0    NaN    NaN   \n",
       "5609901  CA007048421  1980/07/20  1980      7   20   0.0   0.0  172.0   89.0   \n",
       "4833304  CA007040440  1999/08/27  1999      8   27   0.0   0.0  215.0  128.0   \n",
       "\n",
       "         TAVG  Latitude  Longitude  Altitude           StationName  \n",
       "7331752  29.0   48.3333   -71.0000     159.0       QC BAGOTVILLE A  \n",
       "1482906   NaN   45.1500   -71.8000     259.0          QC COATICOOK  \n",
       "4424690   NaN   45.9167   -74.2667     290.0      QC MORIN HEIGHTS  \n",
       "5609901   NaN   50.7000   -59.3167       9.0  QC TETE A LA BALEINE  \n",
       "4833304   NaN   49.1333   -68.2000      22.0      QC BAIE-COMEAU A  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['MDPR', 'MDSF', 'WDFG', 'WSFG', 'SNWD', 'PGTM', 'WT01',\n",
    "       'WT03', 'WT04', 'WT06', 'WT08', 'WT09', 'WT16', 'WT18', 'Type', 'Code']) \n",
    "data.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Define function to get region from coordinates\n",
    "def get_region(lat, lng):\n",
    "    geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "    location = geolocator.reverse((lat, lng), language=\"en\", exactly_one=True)\n",
    "    if location:\n",
    "        address = location.raw.get('address', {})\n",
    "        region = address.get('region', address.get('state_district', \"Region Not Found\"))\n",
    "        return region\n",
    "    return \"Region Not Found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique combinations of LATITUDE, LONGITUDE, and StationName based on unique \n",
    "unique_coords = data[['Latitude', 'Longitude']].drop_duplicates()\n",
    "unique_coords['Region'] = unique_coords.apply(lambda row: get_region(row['Latitude'], row['Longitude']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2199849</th>\n",
       "      <td>45.3333</td>\n",
       "      <td>-71.4000</td>\n",
       "      <td>Estrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157332</th>\n",
       "      <td>48.1333</td>\n",
       "      <td>-68.4833</td>\n",
       "      <td>Bas-Saint-Laurent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372918</th>\n",
       "      <td>48.9000</td>\n",
       "      <td>-71.7667</td>\n",
       "      <td>Saguenay–Lac-Saint-Jean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318322</th>\n",
       "      <td>45.2500</td>\n",
       "      <td>-72.8500</td>\n",
       "      <td>Estrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937481</th>\n",
       "      <td>46.3667</td>\n",
       "      <td>-72.8000</td>\n",
       "      <td>Mauricie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897048</th>\n",
       "      <td>49.2333</td>\n",
       "      <td>-68.1833</td>\n",
       "      <td>Côte-Nord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521353</th>\n",
       "      <td>45.9167</td>\n",
       "      <td>-71.3167</td>\n",
       "      <td>Chaudière-Appalaches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628283</th>\n",
       "      <td>46.1000</td>\n",
       "      <td>-71.3500</td>\n",
       "      <td>Chaudière-Appalaches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116858</th>\n",
       "      <td>47.9000</td>\n",
       "      <td>-73.8000</td>\n",
       "      <td>Mauricie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517331</th>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.5500</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Latitude  Longitude                   Region\n",
       "2199849   45.3333   -71.4000                   Estrie\n",
       "7157332   48.1333   -68.4833        Bas-Saint-Laurent\n",
       "7372918   48.9000   -71.7667  Saguenay–Lac-Saint-Jean\n",
       "1318322   45.2500   -72.8500                   Estrie\n",
       "937481    46.3667   -72.8000                 Mauricie\n",
       "4897048   49.2333   -68.1833                Côte-Nord\n",
       "1521353   45.9167   -71.3167     Chaudière-Appalaches\n",
       "3628283   46.1000   -71.3500     Chaudière-Appalaches\n",
       "8116858   47.9000   -73.8000                 Mauricie\n",
       "5517331   47.5667   -70.5500       Capitale-Nationale"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_coords.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the name of region in unique_coords and correct if necessary\n",
    "#You can use https://qualificationsquebec.com/le-quebec-et-ses-regions/ to correct it\n",
    "# unique_coords['Region'].unique()\n",
    "#Use rename method to correct name of region if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data and unique_coords based on Latitude and Longitude\n",
    "data = pd.merge(data, unique_coords, on=['Latitude', 'Longitude'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>StationName</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5517331</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>1957/06/01</td>\n",
       "      <td>1957</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517332</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>1957/06/02</td>\n",
       "      <td>1957</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517333</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>1957/06/03</td>\n",
       "      <td>1957</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517334</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>1957/06/04</td>\n",
       "      <td>1957</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517335</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>1957/06/05</td>\n",
       "      <td>1957</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532944</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>2004/04/26</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532945</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>2004/04/27</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532946</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>2004/04/28</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532947</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>2004/04/29</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532948</th>\n",
       "      <td>CA007047770</td>\n",
       "      <td>2004/04/30</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5667</td>\n",
       "      <td>-70.55</td>\n",
       "      <td>91.0</td>\n",
       "      <td>QC ST URBAIN</td>\n",
       "      <td>Capitale-Nationale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15618 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Station        Date  Year  Month  Day   PRCP  SNOW   TMAX  TMIN  \\\n",
       "5517331  CA007047770  1957/06/01  1957      6    1    0.0   0.0  283.0  78.0   \n",
       "5517332  CA007047770  1957/06/02  1957      6    2  201.0   0.0  178.0  83.0   \n",
       "5517333  CA007047770  1957/06/03  1957      6    3    8.0   0.0  178.0   6.0   \n",
       "5517334  CA007047770  1957/06/04  1957      6    4    0.0   0.0  211.0  56.0   \n",
       "5517335  CA007047770  1957/06/05  1957      6    5    0.0   0.0  156.0  -6.0   \n",
       "...              ...         ...   ...    ...  ...    ...   ...    ...   ...   \n",
       "5532944  CA007047770  2004/04/26  2004      4   26    0.0   0.0   40.0 -10.0   \n",
       "5532945  CA007047770  2004/04/27  2004      4   27    0.0   0.0  110.0  10.0   \n",
       "5532946  CA007047770  2004/04/28  2004      4   28    0.0   0.0   75.0   0.0   \n",
       "5532947  CA007047770  2004/04/29  2004      4   29    0.0   0.0  220.0 -30.0   \n",
       "5532948  CA007047770  2004/04/30  2004      4   30    0.0   0.0  260.0  70.0   \n",
       "\n",
       "         TAVG  Latitude  Longitude  Altitude   StationName              Region  \n",
       "5517331   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5517332   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5517333   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5517334   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5517335   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "...       ...       ...        ...       ...           ...                 ...  \n",
       "5532944   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5532945   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5532946   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5532947   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "5532948   NaN   47.5667     -70.55      91.0  QC ST URBAIN  Capitale-Nationale  \n",
       "\n",
       "[15618 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for example for Capitale-Nationale\n",
    "data[data.Region == \"Capitale-Nationale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regions in Quebec # Get fro\n",
    "regions = ['Capitale-Nationale', 'Lanaudière', 'Mauricie', 'Montérégie', 'Laurentides', \n",
    "           'Chaudière-Appalaches', 'Centre-du-Québec', 'Estrie', 'Region Not Found', \n",
    "           'Montreal (administrative region)', 'Outaouais', 'Côte-Nord', 'Saguenay–Lac-Saint-Jean', \n",
    "           'Bas-Saint-Laurent', 'Gaspésie–Îles-de-la-Madeleine', 'Abitibi-Témiscamingue', 'Nord-du-Québec', 'Labrador']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset data for Capitale-Nationale saved to: subset_data_Capitale-Nationale.csv\n",
      "Subset data for Lanaudière saved to: subset_data_Lanaudière.csv\n",
      "Subset data for Mauricie saved to: subset_data_Mauricie.csv\n",
      "Subset data for Montérégie saved to: subset_data_Montérégie.csv\n",
      "Subset data for Laurentides saved to: subset_data_Laurentides.csv\n",
      "Subset data for Chaudière-Appalaches saved to: subset_data_Chaudière-Appalaches.csv\n",
      "Subset data for Centre-du-Québec saved to: subset_data_Centre-du-Québec.csv\n",
      "Subset data for Estrie saved to: subset_data_Estrie.csv\n",
      "Subset data for Region Not Found saved to: subset_data_Region Not Found.csv\n",
      "Subset data for Montreal (administrative region) saved to: subset_data_Montreal (administrative region).csv\n",
      "Subset data for Outaouais saved to: subset_data_Outaouais.csv\n",
      "Subset data for Côte-Nord saved to: subset_data_Côte-Nord.csv\n",
      "Subset data for Saguenay–Lac-Saint-Jean saved to: subset_data_Saguenay–Lac-Saint-Jean.csv\n",
      "Subset data for Bas-Saint-Laurent saved to: subset_data_Bas-Saint-Laurent.csv\n",
      "Subset data for Gaspésie–Îles-de-la-Madeleine saved to: subset_data_Gaspésie–Îles-de-la-Madeleine.csv\n",
      "Subset data for Abitibi-Témiscamingue saved to: subset_data_Abitibi-Témiscamingue.csv\n",
      "Subset data for Nord-du-Québec saved to: subset_data_Nord-du-Québec.csv\n",
      "Subset data for Labrador saved to: subset_data_Labrador.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each region and export corresponding subset to CSV\n",
    "#As file data is huge I prefere split it by each region so i can easily apply further data analysis\n",
    "for region in regions:\n",
    "    subset_data = data[data['Region'] == region]\n",
    "    output_csv_path = f'subset_data_{region}.csv'\n",
    "    subset_data.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Subset data for {region} saved to: {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
